{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f7d1574-6194-4413-8f43-60fdd4063dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install librosa soundfile numpy scikit-learn pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6e4b18f-6e5b-4ae6-a7ea-4e53d6ad6c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import soundfile\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c32cad9-aabd-4a09-91f9-2bcff8f9f76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(file_name, mfcc, chroma, mel, tonnetz, pitch, spectral_centroid, spectral_bandwidth, spectral_rolloff, zero_crossing_rate, rms, intonation, rhythm):\n",
    "    with soundfile.SoundFile(file_name) as sound_file:\n",
    "        X = sound_file.read(dtype=\"float32\")\n",
    "        sample_rate = sound_file.samplerate\n",
    "        if chroma:\n",
    "            stft = np.abs(librosa.stft(X))\n",
    "        result = np.array([])\n",
    "\n",
    "        if mfcc:\n",
    "            mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "            result = np.hstack((result, mfccs))\n",
    "\n",
    "        if chroma:\n",
    "            chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n",
    "            result = np.hstack((result, chroma))\n",
    "\n",
    "        if mel:\n",
    "            mel = np.mean(librosa.feature.melspectrogram(y=X, sr=sample_rate).T, axis=0)\n",
    "            result = np.hstack((result, mel))\n",
    "\n",
    "        if tonnetz:\n",
    "            tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T, axis=0)\n",
    "            result = np.hstack((result, tonnetz))\n",
    "\n",
    "        if pitch:\n",
    "            pitches, magnitudes = librosa.core.piptrack(y=X, sr=sample_rate)\n",
    "            pitch_mean = np.mean(librosa.core.pitch_tuning(pitches))\n",
    "            result = np.hstack((result, pitch_mean))\n",
    "\n",
    "        if spectral_centroid:\n",
    "            centroid = np.mean(librosa.feature.spectral_centroid(y=X, sr=sample_rate))\n",
    "            result = np.hstack((result, centroid))\n",
    "\n",
    "        if spectral_bandwidth:\n",
    "            bandwidth = np.mean(librosa.feature.spectral_bandwidth(y=X, sr=sample_rate))\n",
    "            result = np.hstack((result, bandwidth))\n",
    "\n",
    "        if spectral_rolloff:\n",
    "            rolloff = np.mean(librosa.feature.spectral_rolloff(y=X, sr=sample_rate))\n",
    "            result = np.hstack((result, rolloff))\n",
    "\n",
    "        if zero_crossing_rate:\n",
    "            zero_crossings = np.mean(librosa.feature.zero_crossing_rate(y=X))\n",
    "            result = np.hstack((result, zero_crossings))\n",
    "\n",
    "        if rms:\n",
    "            rms_value = np.mean(librosa.feature.rms(y=X))\n",
    "            result = np.hstack((result, rms_value))\n",
    "            \n",
    "        if intonation:\n",
    "            pitches, magnitudes = librosa.core.piptrack(y=X, sr=sample_rate)\n",
    "            pitch_mean = np.mean(librosa.core.pitch_tuning(pitches))\n",
    "            pitch_std = np.std(librosa.core.pitch_tuning(pitches))\n",
    "            result = np.hstack((result, pitch_mean, pitch_std))\n",
    "\n",
    "        if rhythm:\n",
    "            onset_env = librosa.onset.onset_strength(y=X, sr=sample_rate)\n",
    "            tempo, _ = librosa.beat.beat_track(onset_envelope=onset_env, sr=sample_rate)\n",
    "            result = np.hstack((result, tempo))\n",
    "    \n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88a76527-ced8-4782-a0a7-c651d6e42c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emotions in the RAVDESS dataset\n",
    "emotions = {\n",
    "    '01': 'neutral',\n",
    "    '02': 'calm',\n",
    "    '03': 'happy',\n",
    "    '04': 'sad',\n",
    "    '05': 'angry',\n",
    "    '06': 'fearful',\n",
    "    '07': 'disgust',\n",
    "    '08': 'surprised'\n",
    "} \n",
    "\n",
    "# Emotions to observe\n",
    "observed_emotions = ['neutral', 'calm', 'happy', 'sad', 'angry', 'fearful', 'disgust', 'surprised']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d6b0e50-b993-4bef-934c-51932d9a1c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and extract features for each sound file\n",
    "def load_data(test_size=0.2):\n",
    "    x, y = [], []  # Fix the initialization of y\n",
    "    for file in glob.glob(\"C:\\\\Users\\\\admin\\\\Desktop\\\\ravdess data\\\\Actor_*\\\\*.wav\"):\n",
    "        file_name = os.path.basename(file)\n",
    "        emotion = emotions[file_name.split(\"-\")[2]]\n",
    "        if emotion not in observed_emotions:\n",
    "            continue\n",
    "        feature = extract_feature(file, mfcc=True, chroma=True, mel=True, tonnetz=True, pitch=True, spectral_centroid=True, spectral_bandwidth=True, spectral_rolloff=True, zero_crossing_rate=True, rms=True, intonation=True, rhythm=True)\n",
    "        x.append(feature)\n",
    "        y.append(emotion)\n",
    "    return train_test_split(np.array(x), y, test_size=test_size, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b28ba38e-99e2-4b83-af0d-ade694155369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "x_train, x_test, y_train, y_test = load_data(test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f02b3a0-f29c-45db-bfed-90c5e0ea06da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14a08fe2-b146-4948-9a52-8f8dd88c9be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the shape of the training and testing datasets\n",
    "print((x_train.shape[0], x_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b874e268-e970-4946-90e0-8a517bc7516d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of features extracted\n",
    "print(f'Features extracted: {x_train.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5414246d-fb6a-4092-8532-afd2062d3550",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': [0.1],\n",
    "    'hidden_layer_sizes': [(500,)],\n",
    "    'max_iter': [1000]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(MLPClassifier(learning_rate='adaptive', batch_size=256, epsilon=1e-08), param_grid, cv=5)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Use the best model\n",
    "model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89ffd4c5-5521-4e30-afd8-fe0231bedb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9bb6e39-1d3b-4406-b854-2d5fa688ae1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict for the test set\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d11377b6-5bde-4096-8f5f-3a61da2cee36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8e3d27-167f-4f4d-a1d8-ee10ba4fbb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the accuracy\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423347df-f06a-489b-8767-67fa648786e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report and confusion matrix\n",
    "print(classification_report(y_test, y_pred))\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa9f131-9bbc-458c-a573-aea4cb84f98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to a file\n",
    "pickle.dump(model, open('model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d45cb83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
